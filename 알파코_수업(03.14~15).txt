<03.14>

1) 변수
변수는 데이터 통이다.

2) 함수
함수는 입력과 출력의 관계를 표현한 코드를 패키징한 코드 통이다.

-함수의 정의는 def로 시작하며, 이는 함수를 실행시키는 것이 아닌 코드를 함수명으로 정의하는 것.
-함수를 호출하는 것이 함수의 실행이다.

3)자료구조
-리스트 튜플 셋 딕셔너리
-리스트는 묶음 데이터를 핸들링하기 위해 쓴다. (수정, 추가, 삭제)
-리스트 메서드 7개 : 3추 4삭
-슬라이싱은 칼질 위치 명시
-튜플은 변경 불가능
-셋은 순서x 중복 불가능
-딕셔너리 순서 x , 키-밸류의 쌍
-딕셔너리 선언은 키값을 선언

4)제어문
-조건문과 반복문
-논리적 사고 3가지 : 조건 판단, 규칙 발견 및 체계화(구조화, 수식화), 순서도 판단
-if문은 리딩스킬(컴퓨팅적 사고)
-for문은 리스트(이터러블 객체)의 반복시행을 위한 문법
-while문은 조건이 참인 동안 반복시행

5)내포용법
-A안에 B있다. : 자료구조(리스트) 안에 제어문(for, if) 있다.
-리스트(자료구조) 생성의 편의를 위해 쓴다.

<문제1>
def solution(num_list,n):
    return 1 if n in num_list else 0

num_list = [1,2,3,4,5]
n = 3
solution(num_list,n)

<문제2>
temp_list = {"8기":[39,35,37,38,36],
             "9기":[36,35,37,38,37],
             "10기":[35,39,36,38,38]}

for key in temp_list:
    for temp in temp_list[key]:
        if temp > 38:
            print(key,"휴강")


<문제3>
def solution(my_string,index_list):
    answer = ''
    for i in index_list:
        answer += my_string[i]
    return answer

my_string = "zpiaz"
index_list = [1,2,0,0,3]

solution(my_string,index_list)


<03.15>



## 03.15 수업-----------------------------------------------------------------------------------------------------------------------

    # url = request.get("")  주소 가져오기
    # url.content / url.text   가져온 내용 확이하기(내용은 같으나 형식만 다르다 / html이라 알아볼 수 없음 / content로 확인하는 것이 컴퓨터 입장에서는 좋음)

    # soup = BeautifulSoup(url.content, "lxml")   lxml 파싱 도구로 파싱한다 / soup 안에 웹페이지 정보(html)가 다 들어있음

    # a_tags = soup.select("a.news_tit")   클래스가 news_tit인 a태그를 다 리스트로 가져옴
    
    # 반복문으로 여러개 가져오기
    # a = []
    # for i in a_tags:
        # a.append(i['title'])

    # 반복문으로 가져온 리스트를 딕셔너리로 패킹
    # dict = {"제목": a}

# 실습) 다음 '삼성전자' 연관검색어만 가져오기
import requests
from bs4 import BeautifulSoup

#1) 주소 가져오기
url = requests.get("https://search.daum.net/search?nil_suggest=btn&w=news&DA=SBC&cluster=y&q=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90")
#2) BS 형으로 변환
search = BeautifulSoup(url.content,"lxml")
#3) 상위 태그 아이디에서 하위 태그 가져오기
span_tags = search.select("div#netizen_lists_top span")
#4) 총 몇개인지
len(span_tags)
#4) 반복문으로 다 가져오기
for span_tag in span_tags:
    print(span_tag.text)

    ## 접근 순서
    # - 원하는 태그들 중 하나 선택 -> 태그 확인
    # - 태그 속성 확인
    # - 있다면 바로 select()
    # - len() 확인


# 실습) 뉴스 제목 가져오기
url = requests.get("https://search.daum.net/search?nil_suggest=btn&w=news&DA=SBC&cluster=y&q=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90")
title = BeautifulSoup(url.content,"lxml")
title_tags = title.select("strong.tit-g.clamp-g a")
len(title_tags)
titles = []
for title_tag in title_tags:
    titles.append(title_tag.text)

titles

    # 딕셔너리로 묶기
dict = {"제목": titles}
    # 데이터 프레임으로 변환
import pandas as pd
news_title = pd.DataFrame(dict)
news_title
