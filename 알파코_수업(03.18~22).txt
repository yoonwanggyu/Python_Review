## 03.18 수업------------------------------------------------------------------------------------------------------------------------------------------
    # 웹 크롤링 복습
    # 원하는 태그들만의 공통점 찾기 -> 속성 + 계층구조(상위태그 + 특성)

    # 크롤링시, 인덱싱, 슬라이싱을 select와 함께 적극적으로 활용

    # 섭네일 사진 가져오기
    # 책 정보 html 가져오기 -> 해당 정보 태그 가져오기 -> 정보에 있는 url requests로 다시 불러오기 -> 불러운 url 저장

    # 1) 정보와 똑같이 접속
url = requests.get("https://www.aladin.co.kr/shop/common/wbest.aspx?BestType=Bestseller&BranchType=1&CID=170")
soup = BeautifulSoup(url.content,"lxml")

    # 2) 이미지 태그 찾기
img_tag = soup.select("img.front_cover")[0]
print(img_tag)

    # 3) 이미지 태그에서 'src' 만 가져오기
img_src = img_tag['src']

    # 4) 'src'에 있는 url으로 접속해서 requests.get 적용
img_resp = requests.get(img_src)
img_resp.content

    # 5) 파일에 저장
with open('불변의 법칙.jpg','wb') as f:
    f.write(img_resp.content)


    ## iframe은 파싱이 안된다
    ## 해당 주소 들어가서 파싱해야 된다

    # 1) 
url = 'https://finance.naver.com/sise/sise_index_day.naver?code=KOSPI'
resp = requests.get(url)
    # 2)
soup = BeautifulSoup(resp.content,'lxml')
    # 3)
date = [date.text for date in soup.select("td.date")]
price = [price.text for price in soup.select("td.number_1")[::2]][::2]
diff = [('-' + diff.text.strip() if 'red02' not in diff['class'] else diff.text.strip()) for diff in soup.select("td.rate_down span")]
rate = [rate.text.strip() for rate in soup.select("td.number_1 span.tah")]
volumn = [volumn.text.strip() for volumn in soup.select("td.number_1")[2::4]]
amount = [amount.text.strip() for amount in soup.select("td.number_1")[3::4]]
    #4)
df_ksp200 = pd.DataFrame({"날짜":date,
                          "체결가" : price,
                          "전일비": diff,
                          "등락률" : rate,
                          "거래량" : volumn,
                          "거래대금" : amount})
df_ksp200




