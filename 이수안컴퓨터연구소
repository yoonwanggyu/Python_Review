    # 사이킷런 이해----------------------------------------------------------------------------------------------------------------------------------

        # 1) gridsearchCV
# 최상의 파라미터를 찾게 도와줌

from sklearn.model_selection import GridSearchCV,train_test_split,RandomizedSearchCV
from sklearn.linear_model import LinearRegression,Ridge,Lasso
import pandas as pd
import numpy as np
from sklearn.datasets import load_diabetes

diabetes = load_diabetes()

X = diabetes.data
y = diabetes.target

        # Lasso(L1) / Ridge(L2)
        # Ridge 모델에 사용할 정규화 최상의 파라미터 찾기
alpha = [0.001,0.01,0.1,1,10,100,1000]
param_grid = dict(alpha=alpha)

gs = GridSearchCV(estimator=Ridge(),param_grid=param_grid,cv=10)
result = gs.fit(X,y)

print(f"최적의 점수 : {result.best_score_}")
print(f"최적의 파라미터 : {result.best_params_}")
print(gs.best_estimator_)
pd.DataFrame(result.cv_results_)

        # 2) multiprocessing (병렬 처리를 해줌) 을 이용한 GridSearchCV
import multiprocessing
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

iris = load_iris()
x = iris.data
y = iris.target

param_grid_ = [{'penality' : ['l1','l2'],
               'C' : [0.5,1.0,1.5,1.8,2.0,2.4]}]
gs = GridSearchCV(estimator=LogisticRegression(),param_grid=param_grid_,
                  scoring='accuracy',cv=10,n_jobs=multiprocessing.cpu_count())
result = gs.fit(x,y)

print(f"최적의 점수 : {result.best_score_}")
print(f"최적의 파라미터 : {result.best_params_}")
print(gs.best_estimator_)
pd.DataFrame(result.cv_results_)


        # sklearn 안에 있는 온라인 데이터 => 회귀 문제
from sklearn.datasets import fetch_california_housing
california_house = fetch_california_housing()
california_house
data = pd.DataFrame(california_house.data,columns=california_house.feature_names)
data['target'] = california_house.target
data


        # 3) 데이터 전처리 방법(preprocessing)
                # - 표준화 (x - 평균)/표준편차
                # - 정규화 (x - min(x)) / (max(x) - min(x))

    # StandardScaler - 표준화
from sklearn.preprocessing import StandardScaler,MinMaxScaler
iris_df = pd.DataFrame(iris.data,columns=iris.feature_names)
iris_df.describe()

scaler = StandardScaler()
iris_scaled = scaler.fit_transform(iris_df) # 리턴값은 넘파이
iris_scaled_df = pd.DataFrame(iris_scaled,columns=iris.feature_names)
iris_scaled_df.describe()

X_train,X_test,y_train,y_test = train_test_split(iris_scaled_df,iris.target,test_size=0.2,random_state=42)

model = LogisticRegression()
model.fit(X_train,y_train)

print(f"훈련 데이터 점수 : {model.score(X_train,y_train)}")
print(f"평가 데이터 점수 : {model.score(X_test,y_test)}")


    # MinMaxScaler - 정규화
scaler2 = MinMaxScaler()
iris_scaled_ = scaler2.fit_transform(iris_df)
iris_scaled_df_ = pd.DataFrame(iris_scaled_,columns=iris.feature_names)
iris_scaled_df_.describe()

X_train,X_test,y_train,y_test = train_test_split(iris_scaled_df_,iris.target,test_size=0.2,random_state=42)

model = LogisticRegression()
model.fit(X_train,y_train)

print(f"훈련 데이터 점수 : {model.score(X_train,y_train)}")
print(f"평가 데이터 점수 : {model.score(X_test,y_test)}")


        # 4) 성능 평가 지표
            
            # - 정확도(Accuracy)
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

                # 임의의 데이터 생성(make_classificiation)
X,y = make_classification(n_samples=1000,n_features=2,n_informative=2,
                          n_redundant=0, n_clusters_per_class=1)

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

model = LogisticRegression()
model.fit(X_train,y_train)

print(f"훈련 데이터 점수 : {model.score(X_train,y_train)}")
print(f"평가 데이터 점수 : {model.score(X_test,y_test)}")

predict = model.predict(X_test)
        # 데이터가 균일하지 않을 때도 높게 나올 수 있음 -> 정확도는 딱히....
print(f"정확도 : {accuracy_score(y_test,predict)}")


            # - 오차행렬(Confusion Matrix) - 분류 모델 성능 평가
                # True Positive : 실제로 양성(1)인 샘플을 양성(1)으로 예측
                # False Positive : 실제로 음성(0)인 샘플을 양성(1)으로 예측
                # True Negative : 실제로 음성(0)인 샘플을 음성(0)으로 예측
                # False Negative : 실제로 양성(1)인 샘플을 음성(0)으로 예측
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
confmat = confusion_matrix(y_true=y_test,y_pred=predict)
print(confmat)   # TP  |  FP
                 # FN  |  TN
fix,ax = plt.subplots(figsize = (2,2))
ax.matshow(confmat,cmap=plt.cm.Blues,alpha=0.3)
for i in range(confmat.shape[0]):
    for j in range(confmat.shape[1]):
        ax.text(x=j,y=i,s=confmat[i,j],va='center',ha='center')

plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()


            # - 정밀도 / 재현율
                # 정밀도 = TP / (FP+TP)
                # 재현율 = TP / (FN+TP)
                # 정확도 = (TN + TP) / (TN + FP + FN + TP)
                # 오류율 = (FN + FP) / (TN + FP + FN + TP)
from sklearn.metrics import precision_score,recall_score

precision = precision_score(y_test,predict)
recall = recall_score(y_test,predict)

print(f"정밀도 : {precision}")
print(f"재현율 : {recall}")


            # - F1 Score : 정밀도와 재현율을 결합한 지표
                        # 어느 한쪽으로 치우치지 않을 때 높은 값을 가져감
from sklearn.metrics import f1_score

f1 = f1_score(y_test,predict)
print(f"f1 Score : {f1}")


            # - ROC 곡선 / AUC
                # ROC 곡선은 FPR(False positive rate)이 변할 때 TPR(True positive rate)이 어떻게 변하는지 나타내는 곡선

                # TPR : TP / (FN + TP) = 재현율
                # TNR : TN / (FP + TN) = sensitivity(민감도)
                # FPR : FP / (FP + TN) = 1 - TNR

                # AUC 값은 ROC 곡선 밑에 면적을 구한 값(1에 가까울수록 좋은 값)
from sklearn.metrics import roc_curve

pred_proba_class1 = model.predict_proba(X_test)[:,1]
fprs,tprs,thresholds = roc_curve(y_test,pred_proba_class1)

plt.plot(fprs,tprs,label='ROC')
plt.plot([0,1],[0,1],'--k',label='Random')  # random 직선과 멀어질수록 좋음
start,end = plt.xlim()
plt.xticks(np.round(np.arange(start,end,0.1),2))
plt.xlim(0,1)
plt.ylim(0,1)
plt.xlabel("FPR(1-Sensitivity)")
plt.ylabel("TPR(Recall)")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score

roc_auc = roc_auc_score(y_test,predict)
print(f"ROC AUC Score : {roc_auc}")
